services:
  # Whisper ASR Webservice
  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest
    container_name: audio-ai-whisper
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=faster_whisper
    volumes:
      - whisper_models:/app/models
    networks:
      - audio-ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/docs"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # Audio-AI Backend
  audio-ai:
    build:
      context: ..
      dockerfile: Dockerfile
      target: production
    container_name: audio-ai-backend
    ports:
      - "1993:3000"
    volumes:
      # Mount processed files to host for easy access
      - /Volumes/home/notes/content/raw-ai:/usr/src/app/processed
      # Mount environment file if it exists
      - ../backend/.env:/usr/src/app/.env:ro
    environment:
      # Core Configuration
      - NODE_ENV=production
      - PORT=3000
      # Transcription Provider Configuration
      - TRANSCRIPTION_PROVIDER=openai_whisper_webservice
      # Internal Whisper Service URL
      - WHISPER_SERVICE_URL=http://whisper:9000
      # AI Service Configuration (required)
      - GEMINI_API_KEY=${GEMINI_API_KEY:-your_gemini_api_key_here}
      # Optional Settings
      - MAX_FILE_SIZE_MB=100
      - LOG_LEVEL=info
    depends_on:
      whisper:
        condition: service_healthy
    networks:
      - audio-ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  whisper_models:
    driver: local

networks:
  audio-ai-network:
    driver: bridge
