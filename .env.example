# ==============================================================
# Audio-AI Configuration
# ==============================================================
# Copy this file to .env and configure for your setup

# ==============================================================
# PORT CONFIGURATION
# ==============================================================
# Audio-AI Backend Port (default: 3000)
AUDIO_AI_PORT=3000

# Local Whisper Service Port (default: 9000)
WHISPER_PORT=9000

# Development Port (default: 3001)
AUDIO_AI_DEV_PORT=3001

# ==============================================================
# TRANSCRIPTION PROVIDER CONFIGURATION
# ==============================================================
# Choose your transcription provider:
# - free_web_speech        : Free mock provider (for testing)
# - openai_whisper_webservice : Use Whisper ASR Webservice
# - huggingface           : Hugging Face API
# - gemini_audio          : Google Gemini Audio
# - local_whisper         : Local Whisper installation

TRANSCRIPTION_PROVIDER=openai_whisper_webservice

# ==============================================================
# WHISPER SERVICE CONFIGURATION
# ==============================================================
# For onerahmet/openai-whisper-asr-webservice
# Use one of these options:

# Option 1: Use bundled local Whisper service
WHISPER_SERVICE_URL=http://whisper:9000

# Option 2: Connect to external Whisper service
# WHISPER_SERVICE_URL=http://localhost:1991
# WHISPER_SERVICE_URL=http://host.docker.internal:1991
# WHISPER_SERVICE_URL=http://your-server-ip:9000

# Whisper Model Configuration
WHISPER_MODEL=latest         # Docker image tag: latest, latest-large, etc.
ASR_MODEL=base              # Whisper model: tiny, base, small, medium, large
ASR_ENGINE=openai_whisper   # Engine: openai_whisper, faster_whisper

# ==============================================================
# API KEYS FOR EXTERNAL SERVICES
# ==============================================================

# Required for AI analysis and content generation
GEMINI_API_KEY=your_gemini_api_key_here

# Optional: Hugging Face (if using huggingface provider)
# HUGGINGFACE_API_TOKEN=your_huggingface_token_here

# ==============================================================
# OPTIONAL SETTINGS
# ==============================================================

# Maximum file size for uploads (MB)
MAX_FILE_SIZE_MB=100

# Logging level: debug, info, warn, error
LOG_LEVEL=info

# ==============================================================
# EXAMPLE CONFIGURATIONS
# ==============================================================

# Example 1: Use bundled Whisper service (recommended for new users)
# TRANSCRIPTION_PROVIDER=openai_whisper_webservice
# WHISPER_SERVICE_URL=http://whisper:9000
# GEMINI_API_KEY=your_api_key

# Example 2: Connect to existing Whisper service
# TRANSCRIPTION_PROVIDER=openai_whisper_webservice
# WHISPER_SERVICE_URL=http://host.docker.internal:1991
# GEMINI_API_KEY=your_api_key

# Example 3: Use Hugging Face API
# TRANSCRIPTION_PROVIDER=huggingface
# HUGGINGFACE_API_TOKEN=your_token
# GEMINI_API_KEY=your_api_key

# Example 4: Development with free provider
# TRANSCRIPTION_PROVIDER=free_web_speech
# GEMINI_API_KEY=your_api_key